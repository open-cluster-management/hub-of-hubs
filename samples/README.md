# Getting Started

This document is aimed to provide an example about how to connect to the kafka and consume the message which is generated by the regional hub. In this way, you can get the message from ACM and push to your owned system.

- **consumer**: create a separate consumer which can receive message from the regional hubs.

## Prerequisites

These instructions assume:

- You need to have a global hub setup successfully. You can choose to [setup a global hub environment on the OCP](https://github.com/stolostron/multicluster-global-hub/blob/main/README.md). If you do not have OCP, you can also run `make e2e-setup-start` to [create a local one in your linux machine](https://github.com/stolostron/multicluster-global-hub/blob/719606de0a65eb8d62c9b10932ef8614bc39ccd0/Makefile#L71).

## Consumer 

Set environment variables.
```bash
export KUBECONFIG=</path/to/global_hub_cluster/kubeconfig>
export SECRET_NAMESPACE=<transport-secret-namespace> # default SECRET_NAMESPACE=open-cluster-management
export SECRET_NAME=<transport-secret-name> # default SECRET_NAME=transport-secret
```

Start a cloudevents client which receive message from `status` topic (`go test ./samples/consumer/cloudevents_test.go -v`).
Then create a policy in the global hub (`oc apply -f ./samples/consumer/deploy`) with another panel. 

You can see the it consumes the message:
```bash
$ go test ./samples/consumer/cloudevents_test.go -v
=== RUN   TestCloudeventsConsumer
=====================
Context Attributes,
  specversion: 1.0
  type: StatusBundle
  source: global-hub-manager
  id: kind-hub1.PlacementRule
  time: 2023-02-27T08:47:20.511191625Z
  datacontenttype: application/json
Extensions,
  offset: 0
  size: 255
Data,
  {
    "destination": "",
    "key": "kind-hub1.PlacementRule",
    "id": "kind-hub1.PlacementRule",
    "msgType": "StatusBundle",
    "version": "0.4",
    "payload": "eyJvYmplY3RzIjpbXSwibGVhZkh1Yk5hbWUiOiJraW5kLWh1YjEiLCJidW5kbGVWZXJzaW9uIjp7ImluY2FybmF0aW9uIjowLCJnZW5lcmF0aW9uIjo0fX0="
  }
...
```

Consume message from `status` topic with kafka client. Here we start a background program to submit the offset to brokers periodically, and each time a message is consumed successfully we just mark the message with `sess.MarkMessage(msg, "")`
```
$ go test ./samples/consumer/kafkas_test.go -v
=== RUN   TestKafkaConsumer
>>> commit offset
>>> mark offset
    kafkas_test.go:51: consumed msg 0 - 27: {"destination":"","key":"kind-hub1.PolicyCompleteCompliance","id":"kind-hub1.PolicyCompleteCompliance","msgType":"StatusBundle","version":"0.9","payload":"eyJvYmplY3RzIjpbeyJwb2xpY3lJZCI6Ijg2OGFkN2Q4LTRkMGUtNDEzOC04ZjFiLWEzYTQxOTJkZDFmZSIsIm5vbkNvbXBsaWFudENsdXN0ZXJzIjpbImtpbmQtaHViMS1jbHVzdGVyMSIsImtpbmQtaHViMS1jbHVzdGVyMiJdLCJ1bmtub3duQ29tcGxpYW5jZUNsdXN0ZXJzIjpbXX1dLCJsZWFmSHViTmFtZSI6ImtpbmQtaHViMSIsImJhc2VCdW5kbGVWZXJzaW9uIjp7ImluY2FybmF0aW9uIjowLCJnZW5lcmF0aW9uIjo4fSwiYnVuZGxlVmVyc2lvbiI6eyJpbmNhcm5hdGlvbiI6MCwiZ2VuZXJhdGlvbiI6OX19"}
>>> last commit offset
--- PASS: TestKafkaConsumer (3.64s)
PASS
ok      command-line-arguments  3.654s
```
