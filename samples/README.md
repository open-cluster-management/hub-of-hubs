# Getting Started

This document is aimed to provide an example about how to connect to the kafka and consume the message which is generated by the regional hub. In this way, you can get the message from ACM and push to your owned system.

- **consumer**: create a separate consumer which can receive message from the regional hubs.

## Prerequisites

These instructions assume:

- You need to have a global hub setup successfully. You can choose to [setup a global hub environment on the OCP](https://github.com/stolostron/multicluster-global-hub/blob/main/README.md). If you do not have OCP, you can also run `make e2e-setup-start` to [create a local one in your linux machine](https://github.com/stolostron/multicluster-global-hub/blob/719606de0a65eb8d62c9b10932ef8614bc39ccd0/Makefile#L71).

## Consumer 

Set environment variables.
```bash
export KUBECONFIG=</path/to/global_hub_cluster/kubeconfig>
export SECRET_NAMESPACE=<transport-secret-namespace> # default SECRET_NAMESPACE=open-cluster-management
export SECRET_NAME=<transport-secret-name> # default SECRET_NAME=transport-secret
```
### Cloudevents samples

Start a cloudevents client which receive message from `status` topic. 
```bash
$ go test -run TestCloudeventsConsumer ./samples/consumer -v
```

Then create a policy in the global hub with another panel. 

```bash
$ oc apply -f ./samples/consumer/deploy
```

You can see the cloudevents client consumes the messages:
```bash
$ go test ./samples/consumer/cloudevents_test.go -v
=== RUN   TestCloudeventsConsumer
=====================
Context Attributes,
  specversion: 1.0
  type: StatusBundle
  source: global-hub-manager
  id: kind-hub1.PlacementRule
  time: 2023-02-27T08:47:20.511191625Z
  datacontenttype: application/json
Extensions,
  offset: 0
  size: 255
Data,
  {
    "destination": "",
    "key": "kind-hub1.PlacementRule",
    "id": "kind-hub1.PlacementRule",
    "msgType": "StatusBundle",
    "version": "0.4",
    "payload": "eyJvYmplY3RzIjpbXSwibGVhZkh1Yk5hbWUiOiJraW5kLWh1YjEiLCJidW5kbGVWZXJzaW9uIjp7ImluY2FybmF0aW9uIjowLCJnZW5lcmF0aW9uIjo0fX0="
  }
...
```
Delete the policy from global hub
```
oc delete -f ./samples/consumer/deploy
```

### Kafka samples

Consume message from `status` topic with kafka client. Here we start a background program to submit the offset to brokers periodically, and each time a message is consumed successfully we just mark the message with `sess.MarkMessage(msg, "")`
```bash
$ go test -run TestKafkaConsumer ./samples/consumer -v 
=== RUN   TestKafkaConsumer
>>> commit offset
+++ mark offset
    kafka_test.go:56: consumed msg 0 - 5: {"destination":"","key":"kind-hub1.ControlInfo","id":"kind-hub1.ControlInfo","msgType":"StatusBundle","version":"0.5","payload":"eyJsZWFmSHViTmFtZSI6ImtpbmQtaHViMSIsImJ1bmRsZVZlcnNpb24iOnsiaW5jYXJuYXRpb24iOjAsImdlbmVyYXRpb24iOjV9fQ=="}
...
```
You can run kafka consumer's sample multiple times to observe the changes in offset.
